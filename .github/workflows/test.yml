name: Run regression tests

on:
  push:
    branches:
      - master
  pull_request:
  workflow_dispatch:

jobs:
  check_commit:
    runs-on: ubuntu-latest
    outputs:
      skip: ${{ steps.check_commit.outputs.skip }}
    steps:
      - name: Always run tests on workflow dispatch
        id: early_exit
        if: ${{ github.event_name == 'workflow_dispatch' }}
        run:
          echo skip=true >> "$GITHUB_OUTPUT"
      - uses: actions/checkout@v4
        if: ${{ steps.early_exit.outputs.skip != 'true' }}
        with:
          ref: ${{ github.event.push.after || github.event.pull_request.head.sha || github.event.workflow_dispatch.ref }}
      - name: Check if message contains skip keyword
        id: check_commit
        if: ${{ steps.early_exit.outputs.skip != 'true' }}
        run: |
          message=$(git log -1 --pretty=format:'%B')
          regex="\[skip tests\]"
          if [[ "$message" =~ $regex ]]; then
            echo skip=true >> "$GITHUB_OUTPUT"
          fi
  build:
    name: Benchmark regression test
    runs-on: self-hosted
    container:
      image: firedrakeproject/firedrake:latest
      options: --shm-size 2g

    concurrency:
      group: testing-${{ github.head_ref || github.run_id }}
      cancel-in-progress: true

    needs: check_commit
    if: ${{ needs.check_commit.outputs.skip != 'true' }}

    env:
      OMP_NUM_THREADS: 1

    steps:
      - name: Install prerequisites
        env:
          S3CONFIG: ${{ secrets.S3CONFIG }}
        run: |
          sudo apt update
          sudo apt install -y task-spooler time s3cmd unzip git-lfs
          tsp -S 48
          mkdir -p $HOME/.s3cfg
          echo "${S3CONFIG}" > $HOME/.s3cfg/config
          chmod 600 $HOME/.s3cfg/config
          s3cmd --config=$HOME/.s3cfg/config get --skip-existing s3://gadopt/github-actions/pygplates_0.36.0_py312_amd64.deb
          sudo apt install -y --fix-broken ./pygplates_0.36.0_py312_amd64.deb
          ln -s /usr/lib/pygplates.so /home/firedrake/firedrake/lib/python3.*/site-packages/

      - uses: actions/checkout@v4
        with:
          lfs: true

      - name: Fetch LFS artifacts
        run: |
          git lfs checkout

      - name: Install Python dependencies
        run: |
          . /home/firedrake/firedrake/bin/activate
          python3 -m pip install .[demos,optimisation]

      - name: Get Muller et al 2022 plate reconstructions
        run: |
          s3cmd --config=$HOME/.s3cfg/config get s3://gadopt/github-actions/Muller_etal_2022_SE_1Ga_Opt_PlateMotionModel_v1.2.zip .
          unzip Muller_etal_2022_SE_1Ga_Opt_PlateMotionModel_v1.2.zip -d demos/mantle_convection/gplates_global

      - name: Check out repository linked to Trim et al. (2023)
        uses: actions/checkout@v4
        with:
          repository: seantrim/exact-thermochem-solution
          path: ./flib

      - name: Compile flib (Trim et al., 2023)
        run: |
          . /home/firedrake/firedrake/bin/activate
          cd flib/Python
          rm *.so
          sed -i 's/f2py3/f2py/' create_library.sh
          source create_library.sh
          cp *.so ../../tests/multi_material
        shell: bash

      - name: Run test
        id: run_tests
        run: |
          . /home/firedrake/firedrake/bin/activate
          make -j test
        env:
          GADOPT_LOGLEVEL: INFO
          TS_MAXFINISHED: 100

      - name: Pytest
        id: run_pytest
        run: |
          . /home/firedrake/firedrake/bin/activate
          python -m pytest -m 'not longtest' --junit-xml=test_results.xml

      - name: Pytest report
        uses: mikepenz/action-junit-report@v4
        if: ${{ !cancelled() && steps.run_pytest.conclusion != 'skipped' }}
        with:
          check_name: Test suite report
          report_paths: test_results.xml
          include_passed: true
          annotate_only: true

      - name: Output timing information
        if: ${{ !cancelled() }}
        shell: bash
        run: |
          declare -A timings
          declare -A success

          digest="$(tsp)"

          mkdir test_outputs

          # extract info
          for id in $(awk 'NR>1 { print $1 }' <<< "$digest"); do
            st="$(tsp -i $id)"
            label=$(awk "/^$id[[:space:]]/ { if (match(\$0, /\[[^]]*\]/)) { print substr(\$0, RSTART+1, RLENGTH-2) } }" <<< "$digest")
            command=$(sed -En 's/^Command.*python3? //p' <<< "$st")
            if [ -z "$label" ]; then
              outfile=$command
            else
              outfile="[$label]$command"
            fi
            command="$label${label:+: }$command"
            timings["$command"]=$(sed -n 's/^Time run: //p' <<< "$st")

            tsp -c $id >> "test_outputs/$outfile" || true

            if grep -q "exit code 0" <<< "$st"; then
              success["$command"]=Yes
            else
              success["$command"]=No
              echo "$command failed:"
              tsp -c $id | tail -n 10 || true
              echo $command >> test_outputs/test_output.log
              tsp -c $id >> test_outputs/test_output.log || true
            fi
          done

          # sort by case name
          declare -a cases
          while IFS= read -r -d '' entry; do
            cases+=("$entry")
          done < <(printf "%s\0" "${!timings[@]}" | sort -z)

          printf "## Case timings\nCase | Time | Success?\n---- | ---- | ----\n" >> "$GITHUB_STEP_SUMMARY"
          for case in "${cases[@]}"; do
            printf "%s | %s | %s\n" "$case" ${timings["$case"]} ${success["$case"]} >> "$GITHUB_STEP_SUMMARY"
          done

      - name: Upload run log
        if: ${{ !cancelled() }}
        uses: actions/upload-artifact@v4
        with:
          name: run-log
          path: test_outputs
